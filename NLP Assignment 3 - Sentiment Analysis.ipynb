{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLTK Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal here is to predict the sentiments behind movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the **CategorizedPlaintextCorpusReader** data into **python list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for fileid in mr.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    reviews.append([mr.raw(fileid), tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset first 1000 reviews are negative and later are positives. So we will shuffle the data using **shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in _daylight_ , sylvester stallone breaks no new ground , cinematically speaking , but he covers familiar territory quite well . \\nyesterday , as i was going about my business in the university bookstore , i noticed this stand with these _daylight_ movie posters on it . \\ni had never heard of the movie , so i stopped by to check it out . \\nit turned out that they were giving away free passes to the movie for people who had or applied for the credit card they were offering . \\nso , i shrugged , thought , \" hey , they probably won\\'t give me the card anyway , and i could always use a free movie , \" so i signed up . \\nall in all , i don\\'t think i got that bad of a deal , either . \\nrob cohen , who has previously brought us such films as _dragon : the bruce lee story_ and , more recently , _dragonheart_ ( gee , i wonder if he likes dragons for some reason ? \\nyou think ? ) , now brings us a very nicely executed disaster picture , with fx by industrial light and magic , about the after-effects of an explosion that collapses a busy tunnel between new york and new jersey . \\nsylvester stallone plays kit latura , who is essentially a carbon copy of the character he played in _cliffhanger_ : a paramedic on the outs because he made a mistake that got people killed . \\nwhen the crisis hits , he is in the right place at the right time and takes it upon himself to go in and get everybody out . \\nthere are other similarities to _cliffhanger_ , too ; perhaps the only real difference is that _cliffhanger_ had a villain , where _daylight_\\'s bad guy is mother nature . \\nin fact , had the two movies been made in hong kong , this might have been titled _cliffhanger ii_--it bears the same relationship to that film that most hk film \" sequels \" do to their predecessors . \\nthe first half-hour of _daylight_ is setup . \\nsubplots are woven , and the mechanism of the disaster is assembled . \\nwe meet all the important people . . . toxic waste disposal truck drivers ; a young , frustrated , jilted , rejected playwright ; a family struggling to stay together ; an older couple and their dog ; a truckload of prisoners ; an ad agency executive ; a tunnel police officer ; stallone ; and others . \\nwe watch the trucks trundle toward their destination ; we watch stallone and so many others driving toward the tunnel for their various reasons . \\nand then , thirty minutes into the film , _boom_ . \\nand it\\'s a big one . \\n>from there on in , it\\'s sly stallone to the rescue . \\nand rescue he does , enduring batterings , beatings , falls , repeated immersion in 34-degree water , explosions , mud , rats , and constant setbacks , before going on to save the day , sly-style . \\nagain . . . there\\'s \\nnothing new here . \\nand yet there doesn\\'t need to be . \\nthe fun of _daylight_ is not in the story but in the execution . \\nthe special-effects are first-rate , thanks to industrial light and magic , and the ensemble cast works well together . \\nonce the film hits its stride , it carries the viewer right along to the finish , with very few jars along the way . \\nthis review is copyright 1996 by christopher e . meadows . \\npermission granted for distribution through rec . arts . movies . reviews and all associated archival . \\npermission granted for free redistribution via cyberspace as long as this message remains attached . \\nall other rights reserved to the author . \\n',\n",
       " 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide the dataset into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=reviews[:1500]\n",
    "test=reviews[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a vocabulary for each review and use it to get unigram features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44116\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "vocabulary = [x.lower() for tagged_sent in train for x in tagged_sent[0].split()]\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unigram_features(data,vocab):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        single_feat_vec = []\n",
    "        sent = tup[0].lower() #lowercasing the dataset\n",
    "        for v in vocab:\n",
    "            if sent.__contains__(v):\n",
    "                single_feat_vec.append(1)\n",
    "            else:\n",
    "                single_feat_vec.append(0)\n",
    "        fet_vec_all.append(single_feat_vec)\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_senti_wordnet_features(data):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        sent = tup[0].lower()\n",
    "        words = sent.split()\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for w in words:\n",
    "            senti_synsets = swn.senti_synsets(w.lower())\n",
    "            for senti_synset in senti_synsets:\n",
    "                p = senti_synset.pos_score()\n",
    "                n = senti_synset.neg_score()\n",
    "                pos_score+=p\n",
    "                neg_score+=n\n",
    "                break #take only the first synset (Most frequent sense)\n",
    "        fet_vec_all.append([float(pos_score),float(neg_score)])\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_features(featureList1,featureList2):\n",
    "    # For merging two features\n",
    "    if featureList1==[]:\n",
    "        return featureList2\n",
    "    merged = []\n",
    "    for i in range(len(featureList1)):\n",
    "        m = featureList1[i]+featureList2[i]\n",
    "        merged.append(m)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lables(data):\n",
    "    labels = []\n",
    "    for tup in data:\n",
    "        if tup[1].lower()==\"neg\":\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(prediction, actual):\n",
    "    prediction = list(prediction)\n",
    "    correct_labels = [prediction[i]  for i in range(len(prediction)) if actual[i] == prediction[i]]\n",
    "    precision = float(len(correct_labels))/float(len(prediction))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_time_test(classifier,vocab):\n",
    "    print(\"Enter a sentence: \")\n",
    "    inp = input()\n",
    "    feat_vec_uni = get_unigram_features(inp,vocab)\n",
    "    feat_vec_swn =get_senti_wordnet_features(test_data)\n",
    "    feat_vec = merge_features(feat_vec_uni, feat_vec_swn)\n",
    "\n",
    "    predict = classifier.predict(feat_vec)\n",
    "    if predict[0]==1:\n",
    "        print(\"The sentiment expressed is: positive\")\n",
    "    else:\n",
    "        print(\"The sentiment expressed is: negative\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = get_unigram_features(train,vocabulary) # vocabulary extracted in the beginning\n",
    "training_labels = get_lables(train)\n",
    "\n",
    "test_features = get_unigram_features(test,vocabulary)\n",
    "test_gold_labels = get_lables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_lst=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "Training data\t0.9913333333333333\n",
      "Test data\t0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB(alpha=0.1).fit(training_features,training_labels) #training process\n",
    "\n",
    "print(\"Precision of NB classifier is\")\n",
    "pred = nb_classifier.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = nb_classifier.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of SVM classifier is\n",
      "Training data\t0.5053333333333333\n",
      "Test data\t0.484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=0.01, kernel='sigmoid').fit(training_features,training_labels)\n",
    "print(\"Precision of SVM classifier is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Tree classifier is\n",
      "Training data\t0.5926666666666667\n",
      "Test data\t0.554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, max_features='sqrt', random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Decision Tree classifier is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Logistic Regression is\n",
      "Training data\t1.0\n",
      "Test data\t0.828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Logistic Regression is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLTK Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal here is to predict the sentiments behind tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples as ts\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mypath= 'C:/Users/Tejas/AppData/Roaming/nltk_data/corpora/twitter_samples/'\n",
    "pos = []\n",
    "for line in open (mypath + r'positive_tweets.json', 'r'):\n",
    "    pos.append(json.loads(line))\n",
    "\n",
    "neg = []\n",
    "for line in open (mypath + r'negative_tweets.json', 'r'):\n",
    "    neg.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#colname = [\"created_at\", \"favorite_count\", \"retweet_count\", \"id\", \"place\", \"coordinates\", \"geo\", \"text\"]\n",
    "\n",
    "df0 = []\n",
    "for dic in pos:\n",
    "    ll = []\n",
    "    ll.append(dic['text'])\n",
    "    ll.append(\"pos\")\n",
    "    df0.append(ll)\n",
    "\n",
    "df1 = []\n",
    "for dic in neg:\n",
    "    ll = []\n",
    "    ll.append(dic['text'])\n",
    "    ll.append(\"neg\")\n",
    "    df1.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0.extend(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df0\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=df[:7000]\n",
    "test=df[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19555\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "vocabulary = [x.lower() for tagged_sent in train for x in tagged_sent[0].split()]\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = get_unigram_features(train,vocabulary) # vocabulary extracted in the beginning\n",
    "training_labels = get_lables(train)\n",
    "\n",
    "test_features = get_unigram_features(test,vocabulary)\n",
    "test_gold_labels = get_lables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "Training data\t0.9995714285714286\n",
      "Test data\t0.9863333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB(alpha=0.1).fit(training_features,training_labels) #training process\n",
    "\n",
    "print(\"Precision of NB classifier is\")\n",
    "pred = nb_classifier.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = nb_classifier.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of SVM classifier is\n",
      "Training data\t0.503\n",
      "Test data\t0.493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=0.01, kernel='sigmoid').fit(training_features,training_labels)\n",
    "print(\"Precision of SVM classifier is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Tree classifier is\n",
      "Training data\t0.5354285714285715\n",
      "Test data\t0.5183333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, max_features='sqrt', random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Decision Tree classifier is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Logistic Regression is\n",
      "Training data\t1.0\n",
      "Test data\t0.9996666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Logistic Regression is\")\n",
    "pred = clf.predict(training_features)\n",
    "precision = calculate_precision(pred,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "pred = clf.predict(test_features)\n",
    "precision = calculate_precision(pred,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "pre_lst.append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Dataset)        (Naive Bayes)          (SVM)           (Decision-tree)       (Logistic-Regression) \n",
      "\n",
      "movie_review        0.81                    0.484                 0.554                     0.828\n",
      "\n",
      "twitter_dataset     0.9863333333333333           0.493      0.5183333333333333              0.9996666666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "(Dataset)        (Naive Bayes)          (SVM)           (Decision-tree)       (Logistic-Regression) \n",
    "\n",
    "movie_review        {}                    {}                 {}                     {}\n",
    "\n",
    "twitter_dataset     {}           {}      {}              {}\n",
    "\n",
    "'''.format(*pre_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
